{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.12.0 numpy==1.19.2 albumentations==0.4.3 diffusers opencv-python==4.1.2.30 pudb==2019.2 invisible-watermark imageio==2.9.0 imageio-ffmpeg==0.4.2 pytorch-lightning==1.4.2 omegaconf==2.1.1\n",
        "!pip install test-tube>=0.7.5 streamlit>=0.73.1 einops==0.3.0 torch-fidelity==0.3.0 torchmetrics==0.6.0 kornia==0.6\n",
        "\n",
        "!pip install ftfy ipywidgets matplotlib pyrallis torch==1.12.0 diffusers==0.12.1 transformers==4.26.0 accelerate"
      ],
      "metadata": {
        "id": "81RpuWaD-V5T"
      },
      "id": "81RpuWaD-V5T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Edenzzzz/Stable-Diffusion-Compositions-Analysis.git\n",
        "%cd Stable-Diffusion-Compositions-Analysis/Attend-and-Excite"
      ],
      "metadata": {
        "id": "ujsDfIMU-aMS"
      },
      "id": "ujsDfIMU-aMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96382360",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "96382360"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "import torch\n",
        "\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from pipeline_attend_and_excite import AttendAndExcitePipeline\n",
        "from config import RunConfig\n",
        "from run import run_on_prompt, get_indices_to_alter, read_associated_indices\n",
        "from utils import vis_utils\n",
        "from utils.ptp_utils import AttentionStore\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ca16f6",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "76ca16f6"
      },
      "source": [
        "# Load Model Weights (may take a few minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c1f737",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "86c1f737"
      },
      "outputs": [],
      "source": [
        "NUM_DIFFUSION_STEPS = 50\n",
        "GUIDANCE_SCALE = 7.5\n",
        "MAX_NUM_WORDS = 77\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "stable = AttendAndExcitePipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n",
        "stable = stable.to(torch.float16)\n",
        "tokenizer = stable.tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b49254",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "31b49254"
      },
      "source": [
        "# Pipeline Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_prompts, all_groups, all_indices_to_alter = read_associated_indices(path='multi_obj_prompts_with_association.csv', group_split_char='|',shift_idxs=1)"
      ],
      "metadata": {
        "id": "lL92DPMm821y"
      },
      "id": "lL92DPMm821y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fcff244",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8fcff244"
      },
      "outputs": [],
      "source": [
        "# configurable parameters (see RunConfig for all parameters)\n",
        "# scale factor- intensity of shift by gradient\n",
        "# thresholds- a dictionary for iterative refinement mapping the iteration number to the attention threshold\n",
        "# max_iter_to_alter- maximal inference timestep to apply Attend-and-Excite\n",
        "def run_and_display(prompts: List[str],\n",
        "                    controller: AttentionStore,\n",
        "                    indices_to_alter: List[int],\n",
        "                    groups: List[List[int]], # EDIT\n",
        "                    generator: torch.Generator,\n",
        "                    run_standard_sd: bool = False,\n",
        "                    scale_factor: int = 20,\n",
        "                    thresholds: Dict[int, float] = {0: 0.05, 10: 0.5, 20: 0.8},\n",
        "                    max_iter_to_alter: int = 25,\n",
        "                    display_output: bool = False):\n",
        "    config = RunConfig(prompt=prompts[0],\n",
        "                       run_standard_sd=run_standard_sd,\n",
        "                       scale_factor=scale_factor,\n",
        "                       thresholds=thresholds,\n",
        "                       max_iter_to_alter=max_iter_to_alter)\n",
        "    image = run_on_prompt(model=stable,\n",
        "                          prompt=prompts,\n",
        "                          controller=controller,\n",
        "                          token_indices=indices_to_alter,\n",
        "                          groups=groups, # EDIT\n",
        "                          seed=generator,\n",
        "                          config=config)\n",
        "    if display_output:\n",
        "        display(image)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84208dee",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "84208dee"
      },
      "source": [
        "# Show Cross-Attention Per Strengthened Token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65528a3a",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "65528a3a"
      },
      "source": [
        "## Define your seeds, prompt and the indices to strengthen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83857ba1",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "83857ba1"
      },
      "outputs": [],
      "source": [
        "# prompt = \"an elephant with a crown\"\n",
        "i= 11\n",
        "prompt = all_prompts[i]\n",
        "token_indices = all_indices_to_alter[i]\n",
        "token_groups = all_groups[i]\n",
        "seeds = [21]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c36fcb",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c1c36fcb"
      },
      "outputs": [],
      "source": [
        "# token_indices = get_indices_to_alter(stable, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05938cab",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "05938cab"
      },
      "source": [
        "## Stable Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a652ee95",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a652ee95"
      },
      "outputs": [],
      "source": [
        "for seed in seeds:\n",
        "    g = torch.Generator('cuda').manual_seed(seed)\n",
        "    prompts = [prompt]\n",
        "    controller = AttentionStore()\n",
        "    image = run_and_display(prompts=prompts,\n",
        "                            controller=controller,\n",
        "                            indices_to_alter=token_indices,\n",
        "                            groups=None,\n",
        "                            generator=g,\n",
        "                            run_standard_sd=True,\n",
        "                            display_output=True)\n",
        "    vis_utils.show_cross_attention(attention_store=controller,\n",
        "                                   prompt=prompt,\n",
        "                                   tokenizer=tokenizer,\n",
        "                                   res=16,\n",
        "                                   from_where=(\"up\", \"down\", \"mid\"),\n",
        "                                   indices_to_alter=token_indices,\n",
        "                                   orig_image=image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35007afe",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "35007afe"
      },
      "source": [
        "## Attend-and-Excite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ba2464b",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false,
        "id": "5ba2464b"
      },
      "outputs": [],
      "source": [
        "for seed in seeds:\n",
        "    g = torch.Generator('cuda').manual_seed(seed)\n",
        "    prompts = [prompt]\n",
        "    controller = AttentionStore()\n",
        "    image = run_and_display(prompts=prompts,\n",
        "                            controller=controller,\n",
        "                            indices_to_alter=token_indices,\n",
        "                            groups=None, # regular AE\n",
        "                            generator=g,\n",
        "                            run_standard_sd=False,\n",
        "                            display_output=True)\n",
        "    vis_utils.show_cross_attention(attention_store=controller,\n",
        "                                   prompt=prompt,\n",
        "                                   tokenizer=tokenizer,\n",
        "                                   res=16,\n",
        "                                   from_where=(\"up\", \"down\", \"mid\"),\n",
        "                                   indices_to_alter=token_indices,\n",
        "                                   orig_image=image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AE with New Losses"
      ],
      "metadata": {
        "id": "4LYQS3_7-LOh"
      },
      "id": "4LYQS3_7-LOh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8802015",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e8802015"
      },
      "outputs": [],
      "source": [
        "for seed in seeds:\n",
        "    g = torch.Generator('cuda').manual_seed(seed)\n",
        "    prompts = [prompt]\n",
        "    controller = AttentionStore()\n",
        "    image = run_and_display(prompts=prompts,\n",
        "                            controller=controller,\n",
        "                            indices_to_alter=token_indices,\n",
        "                            groups=token_groups, # new losses\n",
        "                            generator=g,\n",
        "                            run_standard_sd=False,\n",
        "                            display_output=True)\n",
        "    vis_utils.show_cross_attention(attention_store=controller,\n",
        "                                   prompt=prompt,\n",
        "                                   tokenizer=tokenizer,\n",
        "                                   res=16,\n",
        "                                   from_where=(\"up\", \"down\", \"mid\"),\n",
        "                                   indices_to_alter=token_indices,\n",
        "                                   orig_image=image)\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}